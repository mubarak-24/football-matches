# backend/news.py
from __future__ import annotations

import datetime as dt
import os
import re
from typing import Iterable
from urllib.parse import urlparse

import feedparser
import pytz

# --------------------------- Feeds (ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¥Ø¶Ø§ÙØ©) ----------------------------
FEEDS = [
    "https://www.espn.com/espn/rss/soccer/news",
    "https://feeds.bbci.co.uk/sport/football/rss.xml",
    "https://www.theguardian.com/football/rss",
    "https://www.skysports.com/rss/12040",
]

# --------------------------- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø¶Ø¨Ø· -----------------------------
# ØªÙ‚Ø¯Ø± ØªØºÙŠÙ‘Ø±Ù‡Ø§ Ù…Ù† .env
NEWS_MAX = int(os.getenv("NEWS_MAX", "8"))
NEWS_HOURS = int(os.getenv("NEWS_HOURS", "24"))           # Ù„Ù„Ù†Ø§ÙØ°Ø© Ø§Ù„Ø¹Ø§Ù…Ø©
NEWS_MIN_SCORE = float(os.getenv("NEWS_MIN_SCORE", "2.5"))  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ø¹Ø±Ø¶
DEFAULT_TZ = os.getenv("TIMEZONE", "Asia/Riyadh")

# Ø£Ù†Ø¯ÙŠØ© ÙˆÙƒÙŠÙˆØ±Ø¯Ø² Ù†Ù‡ØªÙ… Ø¨Ù‡Ø§ (EN/AR)
CLUBS = {
    # Spain
    "real madrid": ["real madrid", "madrid", "Ø±ÙŠØ§Ù„ Ù…Ø¯Ø±ÙŠØ¯"],
    "barcelona": ["barcelona", "barÃ§a", "barca", "Ø¨Ø±Ø´Ù„ÙˆÙ†Ø©"],
    # Italy
    "ac milan": ["ac milan", "milan", "Ù…ÙŠÙ„Ø§Ù†"],
    # England
    "manchester united": ["man united", "man utd", "manchester united", "ÙŠÙˆÙ†Ø§ÙŠØªØ¯"],
    "manchester city": ["man city", "manchester city", "Ø§Ù„Ø³ÙŠØªÙŠ"],
    "arsenal": ["arsenal", "Ø¢Ø±Ø³Ù†Ø§Ù„", "Ø§Ø±Ø³Ù†Ø§Ù„"],
    "chelsea": ["chelsea", "ØªØ´ÙŠÙ„Ø³ÙŠ"],
    # Saudi
    "al ahli": ["al ahli", "al-ahli", "alahli", "Ø§Ù„Ø£Ù‡Ù„ÙŠ", "Ø§Ù„Ø£Ù‡Ù„ÙŠ Ø¬Ø¯Ø©", "Ø£Ù‡Ù„ÙŠ Ø¬Ø¯Ø©"],
}

LEAGUE_KEYWORDS = [
    "saudi pro league", "spl", "Ø§Ù„Ø¯ÙˆØ±ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ", "Ø¯ÙˆØ±ÙŠ Ø±ÙˆØ´Ù†", "Ø±ÙˆØ´Ù† Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ",
]

# ÙƒÙ„Ù…Ø§Øª Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ© (ØªØ¹Ø·ÙŠ ÙˆØ²Ù† Ø£Ø¹Ù„Ù‰ Ù„Ù„Ø®Ø¨Ø± Ø§Ù„Ù…Ù‡Ù…)
POS_WORDS = [
    "official", "confirmed", "statement", "signs", "suspended", "injury", "out",
    "return", "deal", "transfer", "joins", "sold", "loan", "sack", "appointed",
    "wins", "beats", "draw", "fixtures", "result", "deadline",
    "Ø±Ø³Ù…ÙŠ", "ØªØ¹Ø§Ù‚Ø¯", "Ø§Ù†ØªÙ‚Ø§Ù„", "Ø¥ÙŠÙ‚Ø§Ù", "Ø¥ØµØ§Ø¨Ø©", "ØºÙŠØ§Ø¨", "Ø¹ÙˆØ¯Ø©", "Ù…Ø¯Ø±Ø¨", "ÙÙˆØ²", "Ø®Ø³Ø§Ø±Ø©", "ØªØ¹Ø§Ø¯Ù„",
]

# Ø£Ù†Ù…Ø§Ø· Ø£Ø®Ø¨Ø§Ø± Ø¶Ø¹ÙŠÙØ©/Ø¥Ø´Ø§Ø¹Ø§Øª Ù„Ø®ÙØ¶ Ø§Ù„ÙˆØ²Ù†
NEG_PATTERNS = [
    r"\brumou?r\b", r"\brumou?rs\b", r"\bgossip\b", r"\btalk\b", r"\blinked\b",
    r"\bset to\b", r"\breportedly\b", r"\bconsidering\b", r"\bclose to\b",
    r"Ù…ØµØ¯Ø±|Ø¥Ø´Ø§Ø¹Ø©|ØªÙ‚Ø§Ø±ÙŠØ±|Ù…Ø±Ø´Ø­|Ù‚Ø¯|ÙŠØ±ØªØ¨Ø·|Ù…Ø­ØªÙ…Ù„",
]
NEG_RX = [re.compile(p, re.I) for p in NEG_PATTERNS]


# ------------------------------- Helpers --------------------------------------
def _norm(s: str) -> str:
    return (s or "").strip().lower()


def _source_weight(source_lc: str) -> float:
    # Boost Ø¨Ø³ÙŠØ· Ù„Ø¨Ø¹Ø¶ Ø§Ù„Ù…ØµØ§Ø¯Ø±
    if "bbc" in source_lc:
        return 1.15
    if "guardian" in source_lc:
        return 1.1
    if "skysports" in source_lc:
        return 1.05
    if "espn" in source_lc:
        return 1.0
    return 1.0


def _club_hit_score(title_lc: str, src_lc: str) -> float:
    score = 0.0
    for aliases in CLUBS.values():
        for a in aliases:
            a_lc = a.lower()
            if a_lc and (a_lc in title_lc or a_lc in src_lc):
                score += 2.0  # Boost Ù‚ÙˆÙŠ Ù„Ø°ÙƒØ± Ø§Ù„Ù†Ø§Ø¯ÙŠ
                break
    return score


def _league_hit_score(title_lc: str, src_lc: str) -> float:
    score = 0.0
    for kw in LEAGUE_KEYWORDS:
        kw_lc = kw.lower()
        if kw_lc in title_lc or kw_lc in src_lc:
            score += 1.5
    return score


def _pos_words_score(title_lc: str) -> float:
    hits = sum(1 for w in POS_WORDS if w.lower() in title_lc)
    return min(hits, 3) * 0.6  # Ø¹ÙˆØ§Ø¦Ø¯ Ù…ØªÙ†Ø§Ù‚ØµØ©


def _neg_words_penalty(title_lc: str) -> float:
    penalty = 0.0
    for rx in NEG_RX:
        if rx.search(title_lc):
            penalty += 0.8
    return penalty


def _score_item(title: str, source: str) -> float:
    t = _norm(title)
    s = _norm(source)
    base = 0.0
    base += _club_hit_score(t, s)
    base += _league_hit_score(t, s)
    base += _pos_words_score(t)
    base -= _neg_words_penalty(t)
    base *= _source_weight(s)
    return base


def _within_local_day(dt_utc: dt.datetime, tzname: str, target_day: dt.date) -> bool:
    """
    ØªØ­ÙˆÙ‘Ù„ Ø²Ù…Ù† UTC Ù„Ù€ timezone Ø§Ù„Ù…Ø­Ø¯Ø¯ ÙˆØªØªØ­Ù‚Ù‚ Ø¥Ù† Ø§Ù„Ø®Ø¨Ø± Ø¯Ø§Ø®Ù„ Ù†ÙØ³ ØªØ§Ø±ÙŠØ® target_day (Ù…Ø­Ù„ÙŠÙ‹Ø§).
    """
    tz = pytz.timezone(tzname)
    local_dt = dt_utc.astimezone(tz)
    return local_dt.date() == target_day


def _iter_feeds(feeds: Iterable[str]) -> Iterable[tuple[str, list]]:
    """
    Generator ÙŠØ±Ø¬Ù‘Ø¹ (source_title, entries) Ù„ÙƒÙ„ ÙÙŠØ¯.
    """
    for url in feeds:
        try:
            feed = feedparser.parse(url)
        except Exception:
            continue
        meta = getattr(feed, "feed", {}) or {}
        fallback = urlparse(url).netloc
        source = meta.get("title") or fallback
        entries = getattr(feed, "entries", []) or []
        yield source, entries


# ------------------------------ Core fetchers ---------------------------------
def fetch_news(
    max_items: int | None = None,
    hours_back: int | None = None,
) -> list[dict]:
    """
    ÙŠØ¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¶Ù…Ù† Ù†Ø§ÙØ°Ø© Ø²Ù…Ù†ÙŠØ© Ù…Ø­Ø¯Ø¯Ø© (Ø§ÙØªØ±Ø§Ø¶ÙŠ 24 Ø³Ø§Ø¹Ø©):
    ÙŠØ¹ÙŠØ¯ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø¹Ù†Ø§ØµØ±: [{title, source, link, published, score}]
    """
    max_items = max_items or NEWS_MAX
    hours_back = hours_back or NEWS_HOURS

    now = dt.datetime.utcnow().replace(tzinfo=dt.timezone.utc)
    cutoff = now - dt.timedelta(hours=hours_back)

    items: list[dict] = []
    for source, entries in _iter_feeds(FEEDS):
        src_lc = _norm(source)
        for e in entries:
            # parse published time (UTC-naiveâ†’make it UTC-aware)
            published = None
            if getattr(e, "published_parsed", None):
                published = dt.datetime(*e.published_parsed[:6], tzinfo=dt.timezone.utc)
            elif getattr(e, "updated_parsed", None):
                published = dt.datetime(*e.updated_parsed[:6], tzinfo=dt.timezone.utc)

            if published and published < cutoff:
                continue

            title = (e.get("title") or "").strip()
            link = e.get("link") or ""
            if not title:
                continue

            score = _score_item(title, source)
            items.append(
                {
                    "title": title,
                    "link": link,
                    "source": source,
                    "published": published.isoformat() if published else "",
                    "score": round(score, 3),
                }
            )

    # de-dup by normalized title
    seen: set[str] = set()
    deduped: list[dict] = []
    for it in items:
        key = _norm(it["title"])
        if key and key not in seen:
            seen.add(key)
            deduped.append(it)

    # filter by score
    filtered = [it for it in deduped if it["score"] >= NEWS_MIN_SCORE]

    # sort by (score desc, published desc)
    filtered.sort(key=lambda x: (x["score"], x.get("published") or ""), reverse=True)

    # fallback: Ù„Ùˆ Ù…Ø§ÙÙŠ Ø´ÙŠØ¡ ÙÙˆÙ‚ Ø§Ù„Ø¹ØªØ¨Ø©ØŒ Ø±Ø¬Ù‘Ø¹ Ø£Ø¹Ù„Ù‰ 3 Ø¹Ø§Ù„Ø£Ù‚Ù„
    if not filtered:
        deduped.sort(key=lambda x: (x["score"], x.get("published") or ""), reverse=True)
        filtered = deduped[: min(3, max_items)]

    return filtered[:max_items]


def fetch_yesterday_news(
    max_items: int | None = None,
    tz: str | None = None,
) -> list[dict]:
    """
    ÙŠØ¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„ØªÙŠ Ù†Ø´Ø±Øª Ø®Ù„Ø§Ù„ "Ø£Ù…Ø³" ÙÙ‚Ø· (Ø­Ø³Ø¨ timezone Ø§Ù„Ù…Ù…Ø±Ù‘Ø±).
    ÙŠØ­ÙˆÙ‘Ù„ ÙˆÙ‚Øª Ø§Ù„Ù†Ø´Ø± Ù„Ù€ timezone Ù…Ø­Ù„ÙŠ ÙˆÙŠØªØ­Ù‚Ù‚ Ù…Ù† ØªØ§Ø±ÙŠØ® Ø£Ù…Ø³ Ø§Ù„Ù…Ø­Ù„ÙŠ.
    """
    max_items = max_items or NEWS_MAX
    tz = tz or DEFAULT_TZ
    tzinfo = pytz.timezone(tz)

    # Ø­Ø¯Ù‘Ø¯ ÙŠÙˆÙ… "Ø£Ù…Ø³" Ø§Ù„Ù…Ø­Ù„ÙŠ
    now_local = dt.datetime.now(tzinfo)
    yday_local_date = (now_local - dt.timedelta(days=1)).date()

    items: list[dict] = []
    for source, entries in _iter_feeds(FEEDS):
        for e in entries:
            published_utc = None
            if getattr(e, "published_parsed", None):
                published_utc = dt.datetime(*e.published_parsed[:6], tzinfo=dt.timezone.utc)
            elif getattr(e, "updated_parsed", None):
                published_utc = dt.datetime(*e.updated_parsed[:6], tzinfo=dt.timezone.utc)

            # Ù„Ùˆ Ù…Ø§ Ø¹Ø±ÙÙ†Ø§ ÙˆÙ‚Øª Ø§Ù„Ù†Ø´Ø±ØŒ ØªØ¬Ø§Ù‡Ù„ (Ø­ØªÙ‰ Ù„Ø§ Ù†Ø®Ø§Ø·Ø±)
            if not published_utc:
                continue

            if not _within_local_day(published_utc, tz, yday_local_date):
                continue

            title = (e.get("title") or "").strip()
            if not title:
                continue

            link = e.get("link") or ""
            score = _score_item(title, source)

            items.append(
                {
                    "title": title,
                    "link": link,
                    "source": source,
                    "published": published_utc.isoformat(),
                    "score": round(score, 3),
                }
            )

    # de-dup + filter + sort
    seen: set[str] = set()
    deduped: list[dict] = []
    for it in items:
        key = _norm(it["title"])
        if key and key not in seen:
            seen.add(key)
            deduped.append(it)

    filtered = [it for it in deduped if it["score"] >= NEWS_MIN_SCORE]
    filtered.sort(key=lambda x: (x["score"], x.get("published") or ""), reverse=True)

    if not filtered:
        # fallback: Ø±Ø¬Ù‘Ø¹ Ø£Ø¹Ù„Ù‰ 3 Ù…Ù† Ø£Ù…Ø³ (Ø­ØªÙ‰ Ù„Ùˆ ØªØ­Øª Ø§Ù„Ø¹ØªØ¨Ø©) Ø¹Ø´Ø§Ù† Ù…Ø§ ØªØ·Ù„Ø¹ ÙØ§Ø±ØºØ©
        deduped.sort(key=lambda x: (x["score"], x.get("published") or ""), reverse=True)
        filtered = deduped[: min(3, max_items)]

    return filtered[:max_items]


# ----------------------------- Formatters (strings) ---------------------------
def format_news_bulletin(max_items: int | None = None, hours_back: int | None = None) -> str:
    """
    Ù†Ø´Ø±Ø© Ø£Ø®Ø¨Ø§Ø± Ù„Ø¢Ø®Ø± N Ø³Ø§Ø¹Ø© (Ø§ÙØªØ±Ø§Ø¶ÙŠ 24h).
    """
    items = fetch_news(max_items=max_items, hours_back=hours_back)
    if not items:
        return "ğŸ“° Football News (last 24h)\n- Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¹Ù†Ø§ÙˆÙŠÙ† Ù…Ù‡Ù…Ø© Ø§Ù„Ø¢Ù†."
    lines = ["ğŸ“° Football News (last 24h â€” filtered)"]
    for it in items:
        lines.append(f"- [{it['source']}] {it['title']}  (score: {it['score']})\n  {it['link']}")
    return "\n".join(lines)


def format_yesterday_news_bulletin(max_items: int | None = None, tz: str | None = None) -> str:
    """
    Ù†Ø´Ø±Ø© Ø£Ø®Ø¨Ø§Ø± Ù„Ø£Ù…Ø³ ÙÙ‚Ø· (Ø­Ø³Ø¨ Ø§Ù„ØªÙˆÙ‚ÙŠØª Ø§Ù„Ù…Ø­Ù„ÙŠ).
    """
    tz = tz or DEFAULT_TZ
    tzinfo = pytz.timezone(tz)
    yday = (dt.datetime.now(tzinfo) - dt.timedelta(days=1)).date()

    items = fetch_yesterday_news(max_items=max_items, tz=tz)
    if not items:
        return f"ğŸ“° Yesterday's Football News ({yday})\n- Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¹Ù†Ø§ÙˆÙŠÙ† Ù…Ù‡Ù…Ø© Ù„ÙŠÙˆÙ… Ø£Ù…Ø³."

    lines = [f"ğŸ“° Yesterday's Football News ({yday} â€” filtered)"]
    for it in items:
        lines.append(f"- [{it['source']}] {it['title']}  (score: {it['score']})\n  {it['link']}")
    return "\n".join(lines)


# ----------------------------- Manual test runner -----------------------------
if __name__ == "__main__":
    print(format_news_bulletin())
    # or:
    # print(format_yesterday_news_bulletin(tz="Asia/Riyadh"))